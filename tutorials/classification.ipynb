{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kn-pv35t0Yt"
      },
      "source": [
        "# **Preparing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNtVa_jCuL0l"
      },
      "source": [
        "Check the GPU provided (if GPU is not activated: Edit -> Notebook Settings -> Hardware Accelerator -> select GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AzrafipSB43z"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "# https://github.com/googlecolab/colabtools/issues/3409"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "90pw7K44_8Yr",
        "outputId": "fdaa630c-9d5f-421c-8efc-13942236608c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Dec 31 08:39:10 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0              27W /  70W |   1793MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EZYaVHT1huZ7",
        "outputId": "ffd7888b-c233-451a-bd13-00be81048094"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc -V"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asye4V85uQIq"
      },
      "source": [
        "Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bGwy1HqQEQ7p",
        "outputId": "6ef4d243-a4a4-46b2-c930-1382eefd2925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/src\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Iey_nn0xAQBOUiq8Ib8FQYSmB7ouCTtu\n",
            "To: /content/src/data.zip\n",
            "100% 78.9M/78.9M [00:00<00:00, 234MB/s]\n",
            "Archive:  data.zip\n",
            "   creating: test/\n",
            "  inflating: test/test.jpg           \n",
            "  inflating: model.pth               \n",
            "  inflating: model_jit.pth           \n",
            "  inflating: paths.txt               \n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!rm -rf *\n",
        "!mkdir -p /content/src/build/\n",
        "%cd /content/src/\n",
        "!gdown -O data.zip 1Iey_nn0xAQBOUiq8Ib8FQYSmB7ouCTtu\n",
        "!unzip data.zip\n",
        "!rm data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8Vmo5t3u2Gh"
      },
      "source": [
        "After completion, the directory structure includes:\n",
        "```\n",
        "- [src]\n",
        "    - [build]: Torch C++ installation files\n",
        "    - [test]: Sample images\n",
        "    - paths.txt: Paths to the images\n",
        "    - model_jit.pth: PyTorch model converted to TorchScript\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRs67Duxm--A"
      },
      "source": [
        "#**PYTORCH**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CbocK9mStPgd",
        "outputId": "34ec6988-e867-4221-943b-cc45f8e56551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/src\n"
          ]
        }
      ],
      "source": [
        "%cd /content/src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "z0MqmoEowA60"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as tf\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1Gkd1zfpvOJG"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "SCALE_SIZE = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tTUAChE2zF2E"
      },
      "outputs": [],
      "source": [
        "def process_image(im):\n",
        "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "    im = cv2.resize(im, (SCALE_SIZE, SCALE_SIZE), 0.0, 0.0, cv2.INTER_LINEAR)\n",
        "    return im\n",
        "\n",
        "class TestDataset:\n",
        "    def __init__(self, paths_txt='paths.txt'):\n",
        "        df = pd.read_csv(paths_txt, delimiter=' ', header=None)\n",
        "\n",
        "        self.data = list(df[0])\n",
        "\n",
        "        self.tf = tf.Compose([\n",
        "            tf.ToTensor(),\n",
        "            tf.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        im = cv2.imread(self.data[i])\n",
        "        im = process_image(im)\n",
        "        im = self.tf(im)\n",
        "        return im\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "dataset = TestDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQhKjQzhsyxW"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "script_model = torch.jit.load('model_jit.pth')\n",
        "script_model = script_model.to(device)\n",
        "script_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a0S-Uv5Jy_B_",
        "outputId": "d06d52cc-2d4b-4373-9a61-4022303e8e81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time: 23.37158465385437 second(s) (FPS: 43.85667532522063)\n",
            "Dataloading time: 10.550398349761963 second(s) (FPS: 97.15272978513896)\n",
            "Inference time: 0.18727731704711914 second(s) (FPS: 5473.166831742411)\n"
          ]
        }
      ],
      "source": [
        "# Warm up GPU\n",
        "with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        script_model(batch)\n",
        "\n",
        "# Measure total time\n",
        "t1 = time()\n",
        "with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        script_model(batch)\n",
        "t2 = time()\n",
        "\n",
        "print(f\"Total time: {t2 - t1} second(s) (FPS: {len(dataloader.dataset) /(t2 - t1)})\")\n",
        "\n",
        "# Measure dataloading time\n",
        "t1 = time()\n",
        "with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "t2 = time()\n",
        "\n",
        "print(f\"Dataloading time: {t2 - t1} second(s) (FPS: {len(dataloader.dataset) /(t2 - t1)})\")\n",
        "\n",
        "# Measure inference time\n",
        "with torch.no_grad():\n",
        "    t = 0\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        t1 = time()\n",
        "        script_model(batch)\n",
        "        t2 = time()\n",
        "        t += t2 - t1\n",
        "\n",
        "print(f\"Inference time: {t} second(s) (FPS: {len(dataloader.dataset) / t})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5LUjeDgm5y1"
      },
      "source": [
        "#**LIBTORCH**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ybtgpKnynY6Z",
        "outputId": "b98ca566-cc63-4cff-e0fb-3f1385355f76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/src\n"
          ]
        }
      ],
      "source": [
        "%cd /content/src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "786cmBSqpV6W",
        "outputId": "44e4922b-22ad-464a-fdac-134f47357187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "libgif-dev is already the newest version (5.1.9-2build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt -qq install libgif-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d03cS4qP_yb9",
        "outputId": "1f8f1f18-d21f-4bcd-fe36-73aa0ed0143c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replace libtorch/lib/libasmjit.a? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "!wget https://download.pytorch.org/libtorch/nightly/cu101/libtorch-cxx11-abi-shared-with-deps-latest.zip -q\n",
        "!unzip -q libtorch-cxx11-abi-shared-with-deps-latest.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ID5sSDc_Ak93",
        "outputId": "bbef4f55-6311-49f7-82bb-6b042715b17c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing main.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.cpp\n",
        "#include <torch/torch.h>\n",
        "#include <torch/script.h>\n",
        "#include <opencv2/core.hpp>\n",
        "#include <opencv2/imgproc.hpp>\n",
        "#include <opencv2/highgui.hpp>\n",
        "\n",
        "#include <time.h>\n",
        "#include <codecvt>\n",
        "#include <locale>\n",
        "#include <cstddef>\n",
        "#include <cstdio>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "#include <fstream>\n",
        "#include <iostream>\n",
        "#include <string>\n",
        "\n",
        "#define BATCH_SIZE 32\n",
        "#define SCALE_SIZE 300\n",
        "\n",
        "const at::Tensor MEAN = torch::tensor({0.485, 0.456, 0.406});\n",
        "const at::Tensor STD = torch::tensor({0.229, 0.224, 0.225});\n",
        "\n",
        "typedef std::pair<std::string, int> psi;\n",
        "\n",
        "std::vector<psi> convert(std::string infile)\n",
        "{\n",
        "    std::fstream fi;\n",
        "    fi.open(infile, std::fstream::in);\n",
        "\n",
        "    std::string filename;\n",
        "    int label;\n",
        "\n",
        "    std::vector<psi> results;\n",
        "\n",
        "    while (fi >> filename >> label)\n",
        "    {\n",
        "        results.push_back(psi(filename, label));\n",
        "    }\n",
        "\n",
        "    return results;\n",
        "}\n",
        "\n",
        "at::Tensor imageTransform(cv::Mat image)\n",
        "{\n",
        "    // Convert BGR to RGB\n",
        "    cv::cvtColor(image, image, cv::COLOR_BGR2RGB);\n",
        "\n",
        "    // Resize image\n",
        "    cv::Mat resizedImage;\n",
        "    cv::resize(image, resizedImage, cv::Size{SCALE_SIZE, SCALE_SIZE}, 0.0, 0.0, cv::INTER_LINEAR);\n",
        "\n",
        "    // Convert to tensor\n",
        "    at::Tensor image_tensor = torch::from_blob(resizedImage.data, {resizedImage.rows, resizedImage.cols, 3}, at::kByte);\n",
        "    image_tensor = image_tensor / 255.0f;\n",
        "\n",
        "    // Normalize\n",
        "    image_tensor = (image_tensor - MEAN) / STD;\n",
        "\n",
        "    // Transpose H, W, C -> C, H, W\n",
        "    image_tensor = image_tensor.permute({2, 0, 1});\n",
        "\n",
        "    return image_tensor;\n",
        "}\n",
        "\n",
        "class CustomDataset : public torch::data::Dataset<CustomDataset>\n",
        "{\n",
        "private:\n",
        "    // Declare 2 vectors of tensors for images and labels\n",
        "    std::vector<std::string> list_images; // list of path of images\n",
        "public:\n",
        "    // Constructor\n",
        "    CustomDataset(std::string paths_txt)\n",
        "    {\n",
        "        std::vector<psi> paths = convert(paths_txt);\n",
        "        for (int i = 0 ; i < paths.size(); i++)\n",
        "        {\n",
        "            list_images.push_back(paths.at(i).first);\n",
        "        }\n",
        "    };\n",
        "\n",
        "    // Override get() function to return tensor at location index\n",
        "    torch::data::Example<> get(size_t index) override\n",
        "    {\n",
        "        cv::Mat image = cv::imread(list_images.at(index), cv::IMREAD_ANYCOLOR);\n",
        "        torch::Tensor sample_img = imageTransform(image);\n",
        "        torch::Tensor sample_label = torch::zeros(1);\n",
        "        return {sample_img, sample_label};\n",
        "    };\n",
        "\n",
        "    // Return the length of data\n",
        "    torch::optional<size_t> size() const override\n",
        "    {\n",
        "        return list_images.size();\n",
        "    };\n",
        "};\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    auto custom_dataset = CustomDataset(\"../paths.txt\").map(torch::data::transforms::Stack<>());\n",
        "    auto dataset_size = custom_dataset.size().value();\n",
        "\n",
        "    auto data_loader = torch::data::make_data_loader<torch::data::samplers::SequentialSampler>(\n",
        "        std::move(custom_dataset),\n",
        "        BATCH_SIZE\n",
        "    );\n",
        "\n",
        "    torch::Device device(torch::kCUDA);\n",
        "\n",
        "    torch::jit::script::Module module;\n",
        "    try\n",
        "    {\n",
        "        const std::string model_path{argv[1]};\n",
        "        module = torch::jit::load(model_path);\n",
        "        module.to(device);\n",
        "        module.eval();\n",
        "    }\n",
        "    catch (const c10::Error &e)\n",
        "    {\n",
        "        std::cerr << \"Error loading the model\\n\";\n",
        "        std::cerr << e.msg();\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    torch::NoGradGuard no_grad_guard;\n",
        "\n",
        "    // Warmup GPU(s)\n",
        "    for (int i = 0; i < 2; i++) {\n",
        "        for (torch::data::Example<>& batch: *data_loader) {\n",
        "            torch::Tensor data = batch.data;                // Tensor B C W H\n",
        "            std::vector<torch::jit::IValue> inputs;         // IValue\n",
        "            inputs.push_back(data.to(device));              // Tensor2IValue\n",
        "            module.forward(inputs).toTensor();\n",
        "        }\n",
        "    }\n",
        "\n",
        "    auto t1 = std::chrono::system_clock::now();\n",
        "    auto t2 = std::chrono::system_clock::now();\n",
        "    auto total_time = std::chrono::duration_cast<std::chrono::milliseconds>(t2 - t1).count();\n",
        "\n",
        "    // Measure total time\n",
        "    t1 = std::chrono::system_clock::now();\n",
        "    for (torch::data::Example<>& batch: *data_loader) {\n",
        "        torch::Tensor data = batch.data;                // Tensor B C W H\n",
        "        std::vector<torch::jit::IValue> inputs;         // IValue\n",
        "        inputs.push_back(data.to(device));              // Tensor2IValue\n",
        "        module.forward(inputs).toTensor();\n",
        "    }\n",
        "    t2 = std::chrono::system_clock::now();\n",
        "\n",
        "    total_time = std::chrono::duration_cast<std::chrono::milliseconds>(t2 - t1).count();\n",
        "    std::cerr << \"Total time: \" << total_time * 1.0 / 1000 << \" seconds\";\n",
        "    std::cerr << \" (FPS: \" << dataset_size / (total_time * 1.0 / 1000)  << \")\" << std::endl;\n",
        "\n",
        "    // Measure dataloading time\n",
        "    t1 = std::chrono::system_clock::now();\n",
        "    for (torch::data::Example<>& batch: *data_loader) {\n",
        "        torch::Tensor data = batch.data;                // Tensor B C W H\n",
        "        std::vector<torch::jit::IValue> inputs;         // IValue\n",
        "        inputs.push_back(data.to(device));              // Tensor2IValue\n",
        "    }\n",
        "    t2 = std::chrono::system_clock::now();\n",
        "\n",
        "    total_time = std::chrono::duration_cast<std::chrono::milliseconds>(t2 - t1).count();\n",
        "    std::cerr << \"Dataloading time: \" << total_time * 1.0 / 1000 << \" seconds\";\n",
        "    std::cerr << \" (FPS: \" << dataset_size / (total_time * 1.0 / 1000)  << \")\" << std::endl;\n",
        "\n",
        "    // Measure model inference time\n",
        "    total_time = 0;\n",
        "    for (torch::data::Example<>& batch: *data_loader) {\n",
        "        torch::Tensor data = batch.data;                // Tensor B C W H\n",
        "        std::vector<torch::jit::IValue> inputs;         // IValue\n",
        "        inputs.push_back(data.to(device));              // Tensor2IValue\n",
        "        t1 = std::chrono::system_clock::now();\n",
        "        module.forward(inputs).toTensor();\n",
        "        t2 = std::chrono::system_clock::now();\n",
        "        total_time += std::chrono::duration_cast<std::chrono::milliseconds>(t2 - t1).count();\n",
        "    }\n",
        "    std::cerr << \"Inference time: \" << total_time * 1.0 / 1000 << \" seconds\";\n",
        "    std::cerr << \" (FPS: \" << dataset_size / (total_time * 1.0 / 1000)  << \")\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5N9EBuOuAxYH",
        "outputId": "fab64c4b-85ab-4f64-ef37-99f745271d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting CMakeLists.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile CMakeLists.txt\n",
        "cmake_minimum_required(VERSION 3.1)\n",
        "project(inference)\n",
        "find_package(Torch REQUIRED)\n",
        "find_package(OpenCV REQUIRED)\n",
        "find_package(OpenCV COMPONENTS core imgproc highgui REQUIRED)\n",
        "\n",
        "set(CMAKE_EXPORT_COMPILE_COMMANDS ON)\n",
        "\n",
        "include_directories(${OpenCV_INCLUDE_DIRS})\n",
        "include_directories(${Torch_INCLUDE_DIRS})\n",
        "\n",
        "add_executable(run main.cpp)\n",
        "target_link_libraries(run ${TORCH_LIBRARIES} ${OpenCV_LIBRARIES})\n",
        "target_compile_features(run PUBLIC cxx_range_for)\n",
        "set_property(TARGET run PROPERTY CXX_STANDARD 14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WFmhEZODE0Ra",
        "outputId": "58894ddd-ad71-438c-ea9e-b76f390fb356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/src/build\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- Caffe2: CUDA detected: 12.2\n",
            "-- Caffe2: CUDA nvcc is: /usr/local/cuda/bin/nvcc\n",
            "-- Caffe2: CUDA toolkit directory: /usr/local/cuda\n",
            "-- Caffe2: Header version is: 12.2\n",
            "-- Found cuDNN: v8.9.6  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libcudnn.so)\n",
            "\u001b[33mCMake Warning at libtorch/share/cmake/Caffe2/public/cuda.cmake:198 (message):\n",
            "  Failed to compute shorthash for libnvrtc.so\n",
            "Call Stack (most recent call first):\n",
            "  libtorch/share/cmake/Caffe2/Caffe2Config.cmake:88 (include)\n",
            "  libtorch/share/cmake/Torch/TorchConfig.cmake:68 (find_package)\n",
            "  CMakeLists.txt:4 (find_package)\n",
            "\n",
            "\u001b[0m\n",
            "-- Autodetected CUDA architecture(s):  7.5\n",
            "-- Added CUDA NVCC flags for: -gencode;arch=compute_75,code=sm_75\n",
            "-- Found OpenCV: /usr (found version \"4.5.4\") found components: core imgproc highgui \n",
            "-- Configuring done (0.3s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/src/build\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%shell\n",
        "cd /content/src/build/\n",
        "echo \"$(pwd)\"\n",
        "cmake -DCMAKE_PREFIX_PATH=/content/src/libtorch .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ysu-N_cVBB4r",
        "outputId": "324d8979-2c0b-480e-e456-ffb95cfaec7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/src/build\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/run.dir/main.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable run\u001b[0m\n",
            "[100%] Built target run\n",
            "/content/src\n"
          ]
        }
      ],
      "source": [
        "%cd /content/src/build\n",
        "!make -j4\n",
        "%cd /content/src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OkIf_jxHvN7A",
        "outputId": "8bcf3ea5-ad50-417d-da4f-a999eccc7be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/src/build\n",
            "Total time: 8.466 seconds (FPS: 121.073)\n",
            "Dataloading time: 8.461 seconds (FPS: 121.144)\n",
            "Inference time: 0.147 seconds (FPS: 6972.79)\n",
            "/content/src\n"
          ]
        }
      ],
      "source": [
        "%cd /content/src/build\n",
        "!./run ../model_jit.pth\n",
        "%cd /content/src"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TorchScript and PyTorch JIT - Classification",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
